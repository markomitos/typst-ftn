= Теоријске основе

== Федеративно учење

Федеративно учење (_Federated Learning_, FL) је техника машинског учења која
омогућава децентрализовано тренирање модела над поверљивим подацима.
За разлику од традиционалног централизованог приступа, где се сви подаци
прикупљају на једном серверу, FL гарантује да подаци никада не напуштају
оригинални уређај. Овај приступ је кључан за очување поверљивости и
усклађеност са регулативама за заштиту података @fl.

Систем федеративног учења функционише на принципу децентрализоване обуке.
Сваки уређај (клијент) у систему поседује локалну копију дељеног модела.
Локални модел се тренира искључиво коришћењем података који се налазе на
том уређају. Након завршетка локалног тренинга, уређај не шаље своје приватне
податке, већ само ажуриране тежине модела централном серверу.

Централни сервер има улогу агрегатора. Он прикупља ажуриране тежине од
великог броја уређаја и агрегира резултате. Израчунати, побољшани глобални
модел се затим шаље назад свим уређајима у систему, и циклус обуке се понавља.
Процес се изводи итеративно, чиме се временом побољшавају перформансе дељеног
модела, без употребе приватних података.

Потенцијалне области примене федеративног учења су индустрије које захтевају
учење модела над поверљивим скуповима података великог броја корисника, као
што су медицина, роботика и софтверско инжењерство. Најутицајнија примена
FL-а над великим скупом података је предвиђање корисничког уноса на Gboard
Android тастатури. На слици @fig:gboard приказан је примена FL за предвиђање
корисничког уноса на _Gboard Android_ тастатури @gboard.

#figure([#box(width: auto, image("../slike/gboard.jpg"));],
caption: [
  Примена FL за предвиђање корисничког уноса на _Gboard Android_ тастатури.
  Мобилни уређај локално тренира над претходним корисничким уносима и
  ажуриране тежине шаље централном серверу (A). Централни сервер агрегира
  примљене тежине (B) и шаље свим уређајима побољшан дељени модел (C) @gboard.
]
)<fig:gboard>

Кључна предност Федеративног учења је гарантована поверљивост података,
јер подаци остају искључиво на оригиналним уређајима, што омогућава децентрализовано
тренирање. Ова техника, заједно са оптимизованом диференцијалном приватношћу,
базира се на дистрибутивном машинском учењу којим се ефикасно чува поверљивост
тренинг података.

== Оптимизована диференцијална приватност

Диференцијална приватност (_Differential Privacy_, DP) је математички дефинисан оквир
који квантификује и гарантује приватност појединца у оквиру базе података.
Основна идеја је увођење контролисаног шума у процес обраде података,
тако да присуство или одсуство записа једног појединца у скупу података не може значајно
утицати на коначни излаз анализе или модела. Овај концепт пружа гаранцију да нападач
не може са сигурношћу закључити да ли је одређени појединац био део скупа података @dp.

Математичка дефиниција DP се најчешће изражава параметрима $ϵ$ (епсилон) и $δ$ (делта).
Алгоритам $А$ је $(ϵ, δ)$ диференцијално приватан ако за свака два скупа података $D$ и $D'$,
која се разликују за само један узорак и за сваки излазни скуп резултата $S$
важи следећа неједнакост @privacy_book:

#align(center, [
  $ P[A(D) ∈ S] ≤ e^ϵ * P[A(D') ∈ S] + δ $
])

, где је _P_ вероватноћа. Загарантовано је да се вероватноћа добијања било ког излаза
не може променити за фактор већи од $e^ϵ$ ако се један узорак дода или уклони.

Параметар ϵ одређује горњу границу промене вероватноће излаза приликом укључивања
или изостављања једног узорка података. Нижа вредност ϵ означава бољу приватност,
али потенцијално и мању тачност модела. За ϵ једнак нули излази су индентични и
добија се загарантована приватност, што је у пракси немогуће достићи.

Параметар δ представља вероватноћу да горња граница ϵ неће бити задовољена.
У идеалном теоријском случају δ тежи нули, чиме се добија диференцијална приватност
која зависи само од параметра $ϵ$, док се у практичним применама поставља на малу вредност
(нпр. $10^(-5)$), која би требало да буде мања од инверзне вредности величине скупа података
($1/"величина скупа података"$), чиме се смањује ризик угрожавања приватности појединог
 узорка у скупу података.

Оптимизована диференцијална приватност (_Optimized Differential Privacy_, ODP) представља
варијанту примене DP, која је специјализовану за контекст машинског учења и великих,
дистрибуираних система. Главни изазов код стандардне DP је постизање оптималног компромиса
између приватности и тачности модела. ODP користи методе попут клиповања градијента
(_Gradient Clipping_) @dl_dp пре додавања шума, како би се смањио потребан ниво шума
и одржала тачност модела, уз истовремено задовољавање дефинисане ϵ границе приватности.

У контексту дистрибутивног машинског учења, DP се може применити на два начина @ldp_cdp:

- Локална диференцијална приватност (_Local Differential Privacy_, LDP): Шум се додаје
    директно на сирове податке или ажурирања модела на самом уређају (клијенту), чиме се
    добија заштита од злонамерног централног сервера.

- Централна диференцијална приватност (_Central Differential Privacy_, CDP): Шум се додаје
    на централном серверу, након што су прикупљени сви доприноси клијената.
    У FL, шум се додаје на тежине модела приликом агрегације.

Технике FL и DP су комплементарне. FL пружа технички механизам за децентрализацију
тренинга и спречава прикупљање сирових података на серверу, док DP/ODP пружа математичку
гаранцију да чак ни ажурирања модела не могу открити податке појединаца. Применом ODP на
ажуриране тежине модела током процеса агрегације, спречава се да сервер може из модела
закључити осетљиве информације о појединачним тренинг подацима. Ова комбинација је неопходна
за изградњу модерних система машинског учења који су у потпуности усклађени са регулативама
за заштиту података.

== Радно окружење _TensorFlow Federated_ (TFF)

_TensorFlow Federated_ (TFF) је радно окружење отвореног кода које је развила компанија _Google_
са циљем да олакша истраживање и примену FL у реалним окружењима @tff. Поред имплементације
постојећих FL алгоритама, радно окружење TFF пружа и модуларни оквир за истраживање и дизајн
нових дистрибуираних алгоритама. Главна предност је подршка за симулирање FL алгоритама користећи
_TensorFlow_ (TF) моделе над симулираним уређајима.

Архитектура TFF-а је подељена на два главна слоја @tff:

- Федеративни модел API (_Federated Model_ API): слој намењен истраживачима и инжењерима машинског учења. Пружа скуп модула високог нивоа који омогућавају кориснику да постојеће моделе изграђене у TF-у, укључујући и _Keras_ моделе, лако прилагоди за FL окружење. Главна функција овог слоја је аутоматско генерисање FL алгоритама попут федеративног просека (_FedAvg_) из стандардног модела машинског учења.

- Федеративни основни API (_Federated Core_ API): темељ TFF-а, намењен за имплементацију нових FL алгоритама. Федеративни основни API је декларативни језик који омогућава експлицитно дефинисање дистрибуираних рачунарских операција. Овај језик је дизајниран за рад са федеративним типовима података, као што су подаци на клијентима (CLIENTS) и подаци на серверу (SERVER). Све комуникационе операције, као што су агрегација и дифузија (слање модела), дефинишу се експлицитно, омогућавајући потпуну контролу над током података и комуникационом ефикасношћу.

Кључна карактеристика TFF-а је његов систем федеративних типова. За разлику од библиотеке
_TensorFlow_ која ради само са тензорима (низовима података), TFF уводи концепт локације
података. На пример, подаци који се налазе на свим клијентима дефинисани су као {тип}$@$CLIENTS,
док су подаци који се налазе на централном серверу дефинисани као {тип}$@$SERVER.
Јасно раздвајање локације података осигурава да се подаци не могу случајно преместити са
приватне локације на централни сервер, чиме се пружа основна гаранција приватности.

Радно окружење TFF-а нуди подршку за учитавање _Keras_ модела због њихове једноставности
и популарности. TFF користи функцију tff.learning.from\_keras\_model за претварање _Keras_
модела у tff.learning.Model интерфејс. Овај интерфејс омогућава коришћење традиционалног
централизованог тренирања са дистрибуираним FL протоколима. Претворени модел се може
користити за креирање комплетног федеративног итеративног процеса, који дефинише иницијализацију
(initialize) и један корак тренирања (next) у FL циклусу.

Механизам конверзије и адаптације _Keras_ модела је кључан за додавање подршке за верзију 3
библиотеке _Keras_. Постојећа архитектура from\_keras\_model је чврсто везана за архитектуру
_Keras_ 2 библиотеке. Због тога је за подршку новој верзији библиотеке _Keras_ неопходно
рефакторисање компоненти TFF-а које управљају стањем модела, оптимизаторима и метрикама,
како би TFF могао да искористи предности новијих модела за машинско учење.

== Библиотека _Keras_

_Keras_ је библиотека отвореног кода за машинско учење која служи као интерфејс високог нивоа,
омогућавајући једноставно коришћење сложених модела. Примарна сврха је једноставно коришћење
популарних серверских радних окружења (_backend_) за машинско учење, као што су _TensorFlow_, _JAX_ и _PyTorch_.
_Keras_ пружа конзистентан и једноставан апликативни програмски интерфејс
(_Application Programming Interface_, API), који апстрахује сложеност _backend_ имплементације,
што омогућава истраживачима и инжењерима да се фокусирају на дизајн модела @keras.
Такође, _Keras_ подржава учитавање и тренирање модела са екстерних платформи,
попут попут платформе _Kaggle_-а @kaggle.

Док је верзија 2 библиотеке _Keras_ било чврсто везан за _TensorFlow_ као свој примарни _backend_, верзија 3
библиотеке _Keras_ донела је темељну архитектонску промену. Најновија верзија имплементације
библиотеке _Keras_ је у потпуности редизајнирана да постане библиотека која подржава више _backend_
окружења (_multi-backend_), чиме се пружа флексибилност у избору најбољег окружења за специфичан
хардвер или задатак. Због ових промена, _Keras_ 3 је морао да редефинише како се интерно рукује
компонентама попут оптимизатора и метрика.

Главни значај библиотеке _Keras_ 3 за федеративно учење и овај рад лежи у његовим побољшањима
перформанси и скалабилности. _Keras_ 3 је омогућио подршку за учитавање и тренирање модела са
више милијарди параметара, као што је модел _Llama_ 3 @llama3. Нови модели имају знатно боље
перформансе у поређењу са претходним моделима са мањим бројем параметара. Немогућност
коришћења ових напредних модела у TFF-у била је главна мотивација за рефакторисање радног окружења.

Архитектонска промена на _multi-backend_ у библиотеци _Keras_ 3 има директан утицај на
имплементацију TFF-а јер је библиотека _Keras_ 3 увела _stateless_ парадигму за кључне компоненте.
_Stateless_ парагигма представља систем који не чува податке о претходним интеракцијама
са корисником, док _statefull_ парадигма чува претходне интеракције са корисником.
У библиотеци _Keras_ 3, оптимизатори више нису директно _statefull_, већ користе методе
попут stateless_apply(). Ово представља проблем код FL, јер TFF мора експлицитно да рукује
променљивим стањима оптимизатора (optimizer slots) приликом агрегације и дистрибуције.

Слично променама у оптимизаторима, и метрике (Metrics) су прешле на _stateless_ приступ
(нпр. функција stateless_update_state()), што је променило начин на који TFF издваја и агрегира
нефинализоване метрике са клијената. Постојећа функција from_keras_model у TFF-у ослањала
се на имплементацију _Keras_ 2 модела за трансформацију модела, које су у библиотеци
_Keras_ 3 комплетно промењене. Функција би морала бити модификована, да би подржала
нове структуре и понашања нове верзије библиотеке _Keras_.

Тренутна верзија TFF-а подржава само _Keras_ 2, што значајно ограничава коришћење новијих,
напреднијих модела. Додавањем подршке за _Keras_ 3, омогућило би се тренирање над најновијим
моделима, чиме би се знатно побољшало предвиђање претраге (SE) унутар IDE-а, што је крајњи
циљ примене федеративног учења у овом домену.

