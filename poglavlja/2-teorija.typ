= Теоријске основе

== Федеративно учење

Федеративно учење (_Federated Learning_, FL) је техника машинског учења која
омогућава децентрализовано тренирање модела над поверљивим подацима.
За разлику од традиционалног централизованог приступа, где се сви подаци
прикупљају на једном серверу, FL гарантује да подаци никада не напусте
оригинални уређај. Овај приступ је кључан за очување поверљивости и
усклађеност са регулативама за заштиту података @fl.

Систем федеративног учења функционише на принципу децентрализоване обуке.
Сваки уређај (клијент) у систему поседује локалну копију дељеног модела.
Локални модел се тренира искључиво коришћењем података који се налазе на
том уређају. Након завршетка локалног тренинга, уређај не шаље своје приватне
податке, већ само ажуриране тежине модела централном серверу.

Централни сервер има улогу агрегатора. Он прикупља ажуриране тежине од
великог броја уређаја и агрегира резултате. Израчунати, побољшани глобални
модел се затим шаље назад свим уређајима у систему, и циклус обуке се понавља.
Процес се изводи итеративно, чиме се временом побољшавају перформансе дељеног
модела, без употребе приватних података.

Потенцијалне области примене федеративног учења су индустрије које захтевају
учење модела над поверљивим скуповима података великог броја корисника, као
што су медицина, роботика и софтверско инжењерство. Најутицајнија примена
FL-а над великим скупом података је предвиђање корисничког уноса на Gboard
Android тастатури. На слици @fig:gboard приказан је примена FL за предвиђање
корисничког уноса на _Gboard Android_ тастатури @gboard.

#figure([#box(width: auto, image("../slike/gboard.jpg"));],
caption: [
  Примена FL за предвиђање корисничког уноса на _Gboard Android_ тастатури.
  Мобилни уређај локално тренира над претходним корисничким уносима и
  ажуриране тежине шаље централном серверу (A). Централни сервер агрегира
  примљене тежине (B) и шаље свим уређајима побољшан дељени модел (C) @gboard.
]
)<fig:gboard>

Кључна предност Федеративног учења је гарантована поверљивост података,
јер подаци остају искључиво на оригиналним уређајима, што омогућава децентрализовано
тренирање. Ова техника, заједно са оптимизованом диференцијалном приватношћу,
базира се на дистрибутивном машинском учењу којим се ефикасно чува поверљивост
тренинг података.